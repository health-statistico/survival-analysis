---
title: "Survival Analysis"
output: html_document
bibliography: references.bib
---

```{r, include=FALSE}
#this hidden chunk makes sure warning messages and other unnecessary messages generated by the console 
knitr::opts_chunk$set(
  warning=FALSE,
  message=FALSE
  
)
#NOTE: choose.files dialogue box only works on windows
os <- read.csv(choose.files(caption = "Select CSV file for time to event data"))
```

# Getting the data ready

## Creating the survival object

Start by loading your individual patient level data (IPD) into a dataframe. Here I load in data on overall survival and call it `os`, then display the first ten rows. The data contains separate rows representing each patient, with their time-to-event, status (1=died, 0=censored), and treatment group (Everolimus or Belzutifan).

```{r}
#Read OS individual patient data
#These datasets contain right-censoring."status"=1 denotes death/progression, "status"=0 denotes censoring.

os[1:10,]
```

We now want to create a *survival object* out of our survival data, which is a standardised object compatible with many of the survival functions in R. Survival objects are created using the `Surv` function from the `survival` package. We will create a survival object out of the IPD and call it `os_surv_obj`

```{r}
library(survival)
os_surv_obj <- Surv(os$time,os$status)
```

The Kaplan-Meier survival curve may now simply be plotted from the survival object using the `plot` command

```{r}
plot(os_surv_obj)
```

However, our data contained the overall survival (OS) of two separate drugs, but we only have one survival curve here. What has gone wrong?

We can have a look into the survival object by displaying it as a matrix using the `as.data.frame` function. Indexing this with `[1:10,]` tells R to just print the first ten rows and all columns

```{r}
as.matrix(os_surv_obj)[1:10,]
```

From this we can see that the object contains ordered information on the time-to-event for each patient, and the status (died or censored) for each patient. However, it does not distinguish between treatment arms.

By comparing the number of rows in the survival object;

```{r}
nrow(os_surv_obj)
```

with the number of rows in the original patient-level data;

```{r}
nrow(os)
```

we can see that they are the same. So the Kaplan-Meier plot generated earlier using the `plot` function is not distinguishing between the two treatment arms.

## Distinguishing treatment arms

To distinguish between treatment arms, we must use the `survfit` function on the survival object, specifying the original dataset the survival object came from and the column within which represents the treatment arm.

```{r}
fit_km <- survfit(os_surv_obj ~ drug, data = os)
```

Now we may plot the Kaplan-Meier curves of the two treatment arms using the `plot` function

```{r}
plot(fit_km)
```

This plot is rather rudimentary however, we can improve it by using `ggsurvplot` of the `survminer` library

```{r, fig.keep='last'}
library(survminer)
ggsurvplot(fit = fit_km,
           data = os,
           ggtheme = theme_minimal(),
           risk.table = TRUE,
           tables.height = 0.3,
           pval = FALSE,
           xlim = c(0,40),
           break.time.by = 4
)
```

# Testing for proportional hazards

Let's test if the hazard functions for those on drug A and those on drug B are proportional. If the hazard function for those on drug A is $h_A(t)$ and the hazard function for those on drug B is $h_B(t)$, then hazards are said to be proportional if:

$$h_A(t)=\lambda h_B(t)$$

Where $\lambda$ is a constant - so it doesn't vary as $t$ changes.

It is important that the hazards between all levels of any covariate included in a Cox regression are proportional. If there are non-proportional hazards between the levels of any covariate included in a Cox regression, there will be a few problems with its results:

1)  Hazard ratio estimates will be biased

2)  P-values, confidence intervals, and other inferential statistics will likely be incorrect

## Schoenfeld Residuals

The simplest way of testing for proportional hazards between different groups is by fitting a Cox proportional hazard model to the data, and including the separate groups as a covariate (note that fitting the Cox proportional hazards model to the data is another way of saying running a cox regression on it), and then running a statistical test on the residuals of this fit known as a Schoenfeld Residuals Test for proportional hazards. I will outline the process in R below.

We fit the Cox proportional hazards model to the data, including the treatment group, `drug`, as a covariate. Then we look at the results using the `summary` function. Before running the regression we will factor the `drug` column of the `os` dataset using the `factor` command. This command specifies the levels of the categorical variable (`drug`), any not specified as either "Eve" or "Bel" will be ignored in further analysis. Another important thing the factor command does is specify the order of the levels of the categorical variable in our analysis. By choosing "Eve" to be first, we specify this as the reference level, and coefficients generated for relative to this reverence level.

```{r}
os$drug <-factor(os$drug,levels = c("Eve","Bel"))
#os$drug <-factor(os$drug,levels = c("Bel","Eve"))
cox_fit <- coxph(os_surv_obj ~ drug, data = os)
summary(cox_fit)
```

Since we have factored "Eve" as the reference level, the Cox-regression reports the coefficients of "Bel" relative.

The coefficient outputted is the log of the hazard ratio. The exponent of the log-hazard ratio is the hazard ratio, and is handily also outputted by the summary function here. Our interpretation of these hazard ratios is that patients taking the drug belzutifan ("Bel") have a hazard ratio of 0.87 compared with everolimus. This means $\phi$ is equal to 0.87, *if* the proportional hazards assumption holds true when tested.

The interpretation of this hazard ratio is that, compared with patients taking everolimus, patients taking belzutifan have a relative likelihood of experiencing death of 0.87, or have a 13% lower risk of death.

The Cox model assumes that the hazard ratios are constant over time. Schoenfeld residuals are a type of residual calculated at each event time for each covariate generated in a Cox model fit. If there is a pattern in the Schoenfeld residuals which indicates a correlation with time, this suggests that the effect of the covariate on the hazard ratio actually changes with time and isn't constant, despite having held the hazard ratio constant in the fitting of the model.

The Schoenfeld Residuals Test posits the following hypotheses:

$H_0:$ The hazard ratio is constant over time and therefore the proportional hazards assumption holds

$H_a:$ The hazard ratio varies over time and therefore the proportional hazards assumption is violated

Low p-values therefore indicate a violation of the proportional hazards assumption

We can conduct the Schoenfeld Residuals Test for proportional hazards on the fit we generated above using the `cox.zph` command

```{r}
cox.zph(cox_fit)
```

a p-value of 0.25 means we therefore fail to reject the null in favor of the alternate hypothesis at a 95% significance level and conclude that the proportional hazards assumption is not violated.

We can plot the Shoenfeld residuals using the `plot` command, or more elegantly, with the `ggcoxzph` command

```{r, fig.keep='last'}
ggcoxzph(cox.zph(cox_fit))
```

## Log-log plots

Another way to check for proportional hazards is to compare the log of the log of the survival curves of the groups in question.

```{r}
drug_levels <- levels(os$drug)

plot(fit_km, fun = "cloglog", 
     col = c("blue","red"))

legend("topleft",
       legend = drug_levels,
       col = c("blue","red"),
       lty = 1
       )
```

Approximately parallel log-log survival plots are consistent with proportional hazards.

## Non-parametric smoothed hazard function estimation

The `bshazard` function allows for the estimation of the hazard function underlying your data. This function does not assume any parametric distribution of the process generating the data.

```{r}
library(bshazard)

haz_fit_1 <- bshazard(Surv(os[os$drug == "Eve",]$time,event=os[os$drug == "Eve",]$status)~1, verbose = FALSE)

haz_fit_2 <- bshazard(Surv(os[os$drug == "Bel",]$time,event=os[os$drug == "Bel",]$status)~1, verbose = FALSE)

plot(haz_fit_1,
     xlab = "Time (months)",
     ylab = "Hazard Rate",
     col = "blue",
     main = "Estimated hazard functions (smoothed)",
     ylim = c(0.01,0.07))
lines(haz_fit_2, col = "red")
legend("bottom", legend = levels(os$drug), col = c("blue","red"), lty = 1)
```

These hazards do not really look proportional given that they cross over one another, although given their confidence intervals they might still be. Since we failed to reject the hypothesis of non-proportional hazards in the Schoenfeld residuals test, we will proceed as if the hazards are proportional.

# Fitting parametric survival curves when hazards are proportional

When hazards are proportional, we know that $h_a(t)=\phi h_b(t)$. This makes it relatively easy to find extrapolations for both the survival curves, because we can find a good fit for one treatment arm, and simply use the relationship above to solve for the other. $\phi$ is simply the hazard ratio we have already estimated in the Cox proportional-hazards model.

## The mathematical relationship between survival curves when their hazards are proportional

Remember that the survival function $S(t)$ and the hazard function $h(t)$ are simultaneously determined. This means that they are two sides of the same coin, when you have defined one, the other is automatically also defined. They are related such that $S(t)=exp(-\int^t_0 \!h(t)\,dt)$. This means that once you have established that $h_a(t)=\phi h_b(t)$ (i.e. the proportional hazards assumption holds), the survival curve of one arm can be described in terms of the other as so $S_a(t) = (S_b(t))^\phi$. You will likely never have to remember how to get to this result, but the maths is as follows:

$$S_a(t)=exp(-\int^t_0 \!h_a(t)\,dt)$$

Since $$h_a(t)=\phi h_b(t)$$ (This is the mathematical depiction of the proportional hazards assumption!)

\
$$S_a(t)=exp(-\int^t_0 \!\phi h_b(t)\,dt)$$

$$S_a(t)=exp(-\phi \int^t_0 \! h_b(t)\,dt)$$

Since $$\int^t_0\!h_b(t)\,dt=-log(S_b(t))$$ (this is just one way of showing how the hazard and its survival function are related)

$$S_a(t)=exp(\phi log(S_b(t)))$$

$$
S_a(t)=exp(log((S_b(t))^\phi)
$$

$$
S_a(t)=(S_b(t))^\phi
$$

## Two methods for fitting a parametric model

There are two ways you can go from here now that you know the hazards are proportional between the two drugs. Both these methods produce different results and make different assumptions

1)  Fit a parametric distribution to the survival of the patients on one drug, then simply apply the hazard ratio found through the Cox-regression to get the survival of the other using the relationship derived above: $S_a(t)=S_b(t)^\phi$

2)  Fit a parametric distribution to all patients, with drug as a covariate. The sum of the linear predictors give the log hazard ratio (e.g. if there is just one covariate, "drug", the log hazard ratio for patients on that drug compared to those that are not is its estimated coefficient)

### Parametric Regression

As opposed to semi or non-parametric approaches, such as the Kaplan-Meier estimator or Cox-regression, parametric regressions involve the direct estimation of the hazard function underlying your data. To estimate this hazard function, we assume that the survival time, $T$, is distributed according to some pre-existing statistical distribution.

Recall that the hazard function $\lambda(t)$, the survivor function $S(t)$, and the PDF and CDF of survival time $f(t)$ & $F(t)$, are all simultaneously determined. So remember that making an assumption for one of these is the same as making an assumption for any of these! In fact, a statistical distribution is simultaneously characterised by a many different functions which are all used in different contexts. I will only mention the ones used in survival analysis in health economics.

A parametric regression estimates a baseline hazard function (the hazard function where all covariates are equal to zero). The model then specifies a relationship between the covariates and this baseline hazard. Let's take for example the exponential regression, which specifies the following relationship:

$$
h(t|\mathbf{X})=\lambda \mathrm{exp}(\mathbf{X}\boldsymbol{\beta})
$$

Where $\lambda$ is the baseline hazard, which is assumed to be constant in the exponential distribution.

$\mathbf{X}$ is a matrix of covariates.

$\boldsymbol{\beta}$ is the column vector of estimated coefficients (these are estimated via maximum likelihood estimation, not ordinary least squares)

#### Example 1: Exponential regression with one covariate

Here is the simplest example of the model in practice:

Let's say the only covariate is "drug" equal to 0 or 1 (0 for drug a, 1 for drug b).

The model specifies the following hazard function for the patient on drug a:

$$
h_a(t)=\lambda
$$

Whilst the patient on drug b is specified the following hazard function:

$$
h_b(t)=\lambda \mathrm{exp}(\beta)
$$

The hazard ratio is therefore:

$$
\phi=\frac{h_b(t)}{h_a(t)}=\frac{\lambda\mathrm{exp}(\beta)}{\lambda}
$$

$$
\phi=\mathrm{exp}(\beta)
$$

Since the hazard ratio is the exponential of $\beta$, $\beta$ itself is therefore the log of the hazard ratio:

$$
log(\phi)=\beta
$$

Hence why $\beta$ is the log-hazard ratio.

Note also that this model specification implicitly assumes that the hazards between drug a and drug b are proportional, since both $h_a(t)$ and $h_b(t)$ are constant.

#### Example 2: Exponential regression with multiple covariates

Let's specify another exponential model with two covariates, drug {0,1} and age {0,1,2,...}

Recall that the exponential model specifies the following relationship:

$$
h(t|\mathbf{X})=\lambda \mathrm{exp}(\mathbf{X}\boldsymbol{\beta})
$$

Our specification would be:

$$
h(t|Drug,Age)=\lambda \mathrm{exp}(\beta_1Drug+\beta_2Age)
$$

Let's find the hazard ratio between a 25-year old on drug a ($h_a$) to a 33-year old on drug b ($h_b$):

$$h_a(t)=\lambda \mathrm{exp}(\beta_2\cdot25)$$

$$
h_b(t)=\lambda \mathrm{exp}(\beta_1+\beta_2\cdot33)
$$

$$
\phi=\frac{h_b(t)}{h_a(t)}=\frac{\lambda\mathrm{exp}(\beta_1+33\beta_2)}{\lambda\mathrm{exp}(25\beta_2)}
$$

$$
\phi=\mathrm{exp}(\beta_1+33\beta_2-25\beta_2)=\mathrm{exp}(\beta_1+8\beta_2)
$$

Therefore the log-hazard ratio is:

$$
log(\phi)=\beta_1+8\beta_2
$$

This should explain why the sum of the linear predictors ($\mathbf{X}\boldsymbol{\beta}$) of group B minus the sum of the linear predictors for group A gives the log-hazard ratio for group B relative to group A in the exponential distribution.

### Generalising this to other distributions

So given a particular distribution's hazard function, how do we find out how the linear predictors are incorporated when undertaking a regression? As far as I'm aware, there is no set way. So in order to see how your regression is parameterised you should look into the documentation for the software you are using. In R this can be done in the console by using a question mark in front of the package whose documentation you require. In this case you would do `?survreg` or `?flexsurvreg`. Here we see that the models are parameterised according to Kalbleisch & Prentice (2002) chapter 2.

Like the two examples above which include the exponential distribution, I will go through examples from all the other commonly used distributions in the link below.

\*\*Link to write up on all the different distribution regression specifications coming soon\*\*

## Which method to use?

[Earlier](##two-methods-for-fitting-a-parametric-model) I posited that there were two potential routes to go down when generating extrapolated survival curves between two treatment groups when they are not violating the proportional hazards assumption. Let's recap the options:

1)  Fitting a distribution to one arm only, and then applying the hazard ratio obtained in the Cox-regression to obtain the survival from the other arm.

2)  Fitting a distribution to the whole data, including the treatment arm as a covariate.

When used for health technology assessment, option one is favoured. To know why let's recall one of the fundamental aspects of the Cox-proportional hazards model. It does not estimate the baseline hazard function directly but instead lets it float freely. This means it makes weak assumptions about the underlying hazard. Therefore, the hazard ratio estimated in the Cox-regression is estimated without making very strong assumptions.

On the other hand, the hazard ratio estimated in option two (when treatment arm is included as a covariate) is estimated while assuming a parametric form for the underlying hazard function. This is a stronger assumption to make.

One thing to note here is that, whilst option one will still result in a parametric form being assumed for both arms when you apply the hazard ratio, what matters is that the hazard ratios estimated in both options will vary slightly, but the hazard ratio estimated in option one (the cox-regression) will have been estimated under less strong assumptions than option two.

## Finding the best fitting parametric distribution

To find a good fit to apply to the survival curve, we will fit all the standard family of distributions to the survival data, and then pick based on their Akaike information criterion (AIC)/ Bayesian information criterion (BIC). These distributions can be fit using the `survreg` command.

It is very important to note here that AIC/BIC should not be the only criterion on which to base our choice of distribution to be used in an economic evaluation (as outlined by \@. Any extrapolations beyond the clinical trial should be clinically sensible, any assumptions made by the selected distribution should match what is seen in real life.

```{r}
exp_fit <- survreg(os_surv_obj ~ drug,data = os, dist = "exponential")
weibull_fit <- survreg(os_surv_obj ~ drug, data = os, dist = "weibull")
loglogistic_fit <- survreg(os_surv_obj ~ drug, data = os, dist = "loglogistic")
lognormal_fit <- survreg(os_surv_obj ~ drug, data = os, dist = "lognormal")
```

These are the distributions available in base R, the gompertz and gamma distributions are only available in the `flexsurv` package.

```{r}
library(flexsurv)
gompertz_fit <- flexsurvreg(os_surv_obj ~ drug, data = os,dist = "gompertz")
gamma_fit <- flexsurvreg(os_surv_obj ~ drug, data = os, dist = "gamma")
```

The above are fitting the named distributions to the particular data with drug as a covariate but, as we said before, in HTA the preferred way to model under the assumption of proportional hazards is to fit the parametric model to just one of the treatment groups and then use the hazard ratio found in Cox-regression to get the survival of the other treatment group(s).

Also, to remain consistent, we will only use the `flexsurvreg` command now to fit parametric models instead of the more basic `survreg`. See @jackson2016 for more on how this package works under the hood.

```{r}
exp_fit <- flexsurvreg(Surv(time = os[os$drug == "Eve",]$time,event = os[os$drug == "Eve",]$status) ~ 1,data = os[os$drug == "Eve",], dist = "exponential")

weibull_fit <- flexsurvreg(Surv(time = os[os$drug == "Eve",]$time,event = os[os$drug == "Eve",]$status) ~ 1,data = os[os$drug == "Eve",], dist = "weibull")

loglogistic_fit <- flexsurvreg(Surv(time = os[os$drug == "Eve",]$time,event = os[os$drug == "Eve",]$status) ~ 1,data = os[os$drug == "Eve",], dist = "llogis")

lognormal_fit <- flexsurvreg(Surv(time = os[os$drug == "Eve",]$time,event = os[os$drug == "Eve",]$status) ~ 1,data = os[os$drug == "Eve",], dist = "lnorm")

gompertz_fit <- flexsurvreg(Surv(time = os[os$drug == "Eve",]$time,event = os[os$drug == "Eve",]$status) ~ 1,data = os[os$drug == "Eve",], dist = "gompertz")

gamma_fit <- flexsurvreg(Surv(time = os[os$drug == "Eve",]$time,event = os[os$drug == "Eve",]$status) ~ 1,data = os[os$drug == "Eve",], dist = "gamma")
```

We can check the coefficients of any fit by invoking the `coef` command

```{r}
coef(lognormal_fit)
```

If we want to use this fit in a model in excel we can simply input these coefficients into the appropriate distribution function, just be aware that the scale of the reported parameter matches that of the excel formula. The `LOGNORM.DIST` function in excel with the `Cumulative` argument set to `TRUE` returns the value of the CDF up at a given x value. Since the survivor function is one minus the CDF, the following returns survival probability at a given month.

`Excel formula =1-LOGNORM.DIST(month,2.8749194,EXP(0.1444546),TRUE)`

We can view the estimated survival of the event in R by plotting the fit

```{r}
plot(exp_fit, col = "blue", lwd = 4)
lines(weibull_fit, col = "red")
lines(loglogistic_fit, col = "yellow")
lines(lognormal_fit, col = "purple")
lines(gompertz_fit, col = "green")
lines(gamma_fit, col = "orange")

legend("bottomleft",
       legend = c("Exponential","Weibull","Log-logistic","Log-normal","Gompertz", "Gamma"),
       col = c("blue","red","yellow","purple","green","orange"),
       lwd = 2,
       bty = "n")
```

The AIC or BIC of a fitted model can simply be calculated with the `AIC` or `BIC` commands.

```{r}
AIC(exp_fit)
BIC(exp_fit)
```

To be more efficient, let's calculate the AIC and BIC for each model and record the results in a data frame.

```{r}
#create the dataframe
os_aic_bic <- data.frame(
  Model = c("Exponential","Weibull","Loglogistic","Lognormal","Gompertz","Gamma"),
  AIC = c(
    AIC(exp_fit),
    AIC(weibull_fit),
    AIC(loglogistic_fit),
    AIC(lognormal_fit),
    AIC(gompertz_fit),
    AIC(gamma_fit)
  ),
  BIC = c(
    BIC(exp_fit),
    BIC(weibull_fit),
    BIC(loglogistic_fit),
    BIC(lognormal_fit),
    BIC(gompertz_fit),
    BIC(gamma_fit)
  )
)
#display the dataframe
os_aic_bic
```

Here we see that the lognormal is has the lowest AIC and BIC and would be deemed the best fit on these criteria alone.

Now that we have our chosen parametric distribution for $t$, how do we now plot the extrapolated survival curve?

For this we can use the `summary` function on our fitted model. The summary function returns the survival times, their associated probabilities, and its confidence interval.

```{r}
x <- summary(lognormal_fit)[[1]]
x[1:10,]
```

If we pass a set of time points into the summary function on the lognormal fit object, R will extrapolate and interpolate the survival probabilities for the time points we specify. These can then be extracted to be used to inform transition probabilities in markov models. Below I have specified time points for every month up to five years, and plotted the survival probabilities accordingly.

```{r}
time_points <- seq(0,5*12, by = 1) 
extrapolated_survival_curve <- summary(lognormal_fit, t = time_points, type = "survival")
extrapolated_survival_curve <- extrapolated_survival_curve[[1]]
plot(extrapolated_survival_curve$time, extrapolated_survival_curve$est)

```

Here is a portion of the dataframe which can easily be exported to your decision model.

```{r}
extrapolated_survival_curve[1:10,]
```

We could also make the plot a bit more sophisticated, by including the confidence intervals and changing the plot into a continuous line.

```{r}
plot(extrapolated_survival_curve$time, extrapolated_survival_curve$est,
     xlab = "Time (months)",
     ylab = "Survival probability",
     type = "n")
lines(extrapolated_survival_curve$time, extrapolated_survival_curve$est, col = "blue")
lines(extrapolated_survival_curve$time, extrapolated_survival_curve$ucl, col = "red")
lines(extrapolated_survival_curve$time, extrapolated_survival_curve$lcl, col = "red")

legend("bottomleft", legend = c("Extrapolated survival","Confidence interval"), col = c("blue","red"), lwd = 1)
```

Let us also generate the survival curve for the other treatment group. We can do this by using the formula derived earlier

$$
S_b(t)=S_a(t)^\phi
$$

Where $\phi$ is the hazard ratio obtained in the cox regression.

In our extrapolated survival curve dataframe, we can simply generate a new column for this.

```{r}
extrapolated_survival_curve$est_new = extrapolated_survival_curve$est^0.87633
plot(extrapolated_survival_curve$time, extrapolated_survival_curve$est, type = "n", xlab = "time", ylab = "Survival probability")
lines(extrapolated_survival_curve$time, extrapolated_survival_curve$est, col = "blue")
lines(extrapolated_survival_curve$time, extrapolated_survival_curve$est_new, col = "red")
legend("topright",
       legend = c("Everolimus","Belzutifan"),
       col = c("blue","red"),
       lty = 1)
```

Simple maths can be done to get the estimated survival to match whatever your chosen cycle length is. In my model the cycle length is 2 weeks. One month is defined as one twelfth of a year which is defined as 365.25 days. Let's create the series of time points which match the cycle length (expressed in months)

```{r}
#One cycle is 1/((365.25/14)/12) ~= 0.45 months
time_points <- seq(0,12*25,by=1/((365.25/14)/12))
new_extrapolation <- summary(lognormal_fit, t = time_points)[[1]]
new_extrapolation[1:10,]
```

# Recommended Reading

@ishak2013
